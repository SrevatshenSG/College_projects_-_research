{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00511553-a57e-4868-a2a7-0fa4dcdd30f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: qiskit in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.0.0)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (0.16.0)\n",
      "Requirement already satisfied: numpy<3,>=1.17 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (1.15.2)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (1.13.1)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (0.3.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (2.9.0.post0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (4.13.0)\n",
      "Requirement already satisfied: symengine<0.14,>=0.11 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from qiskit) (0.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
      "Requirement already satisfied: pbr>=2.0.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (78.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pennylane in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.40.0)\n",
      "Requirement already satisfied: numpy<2.1 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (1.15.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (3.4.2)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (0.16.0)\n",
      "Requirement already satisfied: autograd in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (1.7.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (0.13.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: autoray>=0.6.11 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (0.7.1)\n",
      "Requirement already satisfied: cachetools in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (5.5.2)\n",
      "Requirement already satisfied: pennylane-lightning>=0.40 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (0.40.0)\n",
      "Requirement already satisfied: requests in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (4.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (24.2)\n",
      "Requirement already satisfied: diastatic-malt in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane) (2.15.2)\n",
      "Requirement already satisfied: scipy-openblas32>=0.3.26 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pennylane-lightning>=0.40->pennylane) (0.3.29.0.0)\n",
      "Requirement already satisfied: astunparse in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from diastatic-malt->pennylane) (1.6.3)\n",
      "Requirement already satisfied: gast in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from diastatic-malt->pennylane) (0.6.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from diastatic-malt->pennylane) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->pennylane) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->pennylane) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->pennylane) (2025.1.31)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in c:\\users\\srevatshen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install qiskit\n",
    "!pip install torch torchvision\n",
    "!pip install pennylane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d494c-4c5b-4574-b914-9ae97ee934ab",
   "metadata": {},
   "source": [
    "SAMPLE SENTENCE TO EMBED USING BERT TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e82d2d-d2cb-4bef-8f6f-bfe7d106dcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load BERT base uncased model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze BERT weights for testing\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"This movie was absolutely amazing!\"\n",
    "\n",
    "# Tokenize and get embeddings\n",
    "tokens = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=32)\n",
    "with torch.no_grad():\n",
    "    outputs = bert(**tokens)\n",
    "\n",
    "# Take the [CLS] token as sentence representation\n",
    "embedding = outputs.last_hidden_state[:, 0, :]  # shape: [1, 768]\n",
    "print(\"BERT embedding shape:\", embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a704c6-de78-4e94-a5d0-f8c8a2eefe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINEAR DIMENSION REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fd4736-7375-4b46-88cd-0b97a80b8c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced embedding shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Linear projection from 768 -> 4 (for 4 qubits)\n",
    "reduce_dim = nn.Linear(768, 4)\n",
    "\n",
    "# Apply projection\n",
    "reduced_embedding = reduce_dim(embedding)\n",
    "print(\"Reduced embedding shape:\", reduced_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d1544-ad4f-4f82-a723-32b27a4c5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTUM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aab323-4e4e-4663-83d7-bc45b6d1b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SET UP OF QUANTUM LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d80fa7e-0725-428f-8a6d-825cf5bc0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pennylane as qml\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952c786f-75ee-4180-bc05-d2298d4007d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Layer\n",
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_circuit(inputs):\n",
    "    for i in range(n_qubits):\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RY(np.pi * inputs[i], wires=i)\n",
    "\n",
    "    for i in range(n_qubits):\n",
    "        qml.CNOT(wires=[i, (i+1) % n_qubits])\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def forward(self, inputs):\n",
    "        return torch.stack([quantum_circuit(x) for x in inputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97edd158-1226-4c48-a041-1d63ac6b43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT + Quantum Hybrid Model\n",
    "class BertQuantumClassifier(nn.Module):\n",
    "    def __init__(self, n_qubits=4):\n",
    "        super(BertQuantumClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(768, n_qubits)\n",
    "        self.quantum_layer = QuantumLayer()\n",
    "        self.classifier = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0]           # [CLS] token\n",
    "        reduced = self.pre_classifier(cls_output)              # -> shape [batch_size, n_qubits]\n",
    "        q_out = self.quantum_layer(reduced)                    # -> quantum output\n",
    "        return self.classifier(q_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924bdc7-975e-42e3-88a2-d69a016c9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA PRE PROCESSING FOR QUANTUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0992048b-e369-4efe-89f5-c2555e440f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\srevatshen\\imdb-emotion-classifier\\data\\imdb_reviews.csv\")\n",
    "df = df[['review', 'sentiment']].dropna()\n",
    "\n",
    "# Encode sentiment labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['review'].tolist(), df['sentiment'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Loaders\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7a835c-042a-4a4c-a8ec-6df74354c70e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a silly film that tries to be a black comedy b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die hard 2 is an altogether unfortunate fiasco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( note : there are spoilers regarding the fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at first glance , it appears that the home alo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as the small boats rock slowly toward the shor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  a silly film that tries to be a black comedy b...          0\n",
       "1  die hard 2 is an altogether unfortunate fiasco...          0\n",
       "2   ( note : there are spoilers regarding the fil...          1\n",
       "3  at first glance , it appears that the home alo...          1\n",
       "4  as the small boats rock slowly toward the shor...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327ae620-0b40-4544-b6da-99cf3e479a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertQuantumClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fefece2-e329-4547-981a-0083fe5d2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48c0de0-94f8-41a0-8c5e-999a887221ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 168.1442 - Accuracy: 58.10% - Time: 332.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 145.1050 - Accuracy: 76.05% - Time: 331.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 128.4902 - Accuracy: 84.10% - Time: 328.30s\n",
      " Quantum model and tokenizer saved to: quantum_model_v2/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "class QuantumCircuit:\n",
    "    def __init__(self, n_qubits):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        weight_shapes = {\"weights\": (1, n_qubits)}\n",
    "\n",
    "        @qml.qnode(self.dev, interface=\"torch\")\n",
    "        def circuit(inputs, weights):\n",
    "            qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "            qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "            return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "        self.q_layer = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.q_layer(inputs)\n",
    "\n",
    "\n",
    "class BertQuantumClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=768, n_qubits=4, num_classes=2):\n",
    "        super(BertQuantumClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(hidden_size, n_qubits)\n",
    "        self.quantum_layer = QuantumCircuit(n_qubits).q_layer\n",
    "        self.classifier = nn.Linear(n_qubits, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "        reduced = self.pre_classifier(cls_output)\n",
    "        q_out = self.quantum_layer(reduced)\n",
    "        return self.classifier(q_out)\n",
    "\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.df.iloc[idx]['review']\n",
    "        sentiment = 1 if self.df.iloc[idx]['sentiment'] == 'pos' else 0\n",
    "        encoding = self.tokenizer(\n",
    "            review,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(sentiment, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertQuantumClassifier().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataset_path = r\"C:\\Users\\srevatshen\\imdb-emotion-classifier\\data\\imdb_reviews.csv\"\n",
    "train_dataset = IMDBDataset(dataset_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f} - Accuracy: {acc:.2f}% - Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "\n",
    "save_path = \"quantum_model_v2\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, \"quantum_model.pth\"))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\" Quantum model and tokenizer saved to: {save_path}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea16e9e-e341-4396-a25c-acd2b6bd3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOADING SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9929f6-2f87-4b49-a9c6-e89215ecce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model architecture\n",
    "model = BertQuantumClassifier().to(device)\n",
    "\n",
    "# Load the saved parameters\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, \"quantum_model.pth\")))\n",
    "\n",
    "model.eval()  # Put model in evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced8881-5f84-4123-a2df-7ebf20c60d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed70f78-8e3e-4ae6-92c9-ec3c0db0732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 50/50 [00:22<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 90.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.95      0.91       207\n",
      "    Positive       0.94      0.85      0.90       193\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.90      0.90       400\n",
      "weighted avg       0.91      0.91      0.90       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs, dim=1)  # Directly use model output for predictions\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"\\nValidation Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Evaluate\n",
    "evaluate(model, val_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imdb-env)",
   "language": "python",
   "name": "imdb-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
